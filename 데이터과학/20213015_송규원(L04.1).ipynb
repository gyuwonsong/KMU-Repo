{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oap-7SHvRUC_",
        "outputId": "69b1ac73-42d7-4bba-ff3e-5d9585d3fd9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "y = tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.],\n",
            "        [7., 8., 9.]])\n",
            "Size: torch.Size([3, 3])\n",
            "Shape: torch.Size([3, 3])\n",
            "차원(랭크): 2\n",
            "x0.shape: torch.Size([1, 3, 3])\n",
            "x1.shape: torch.Size([3, 1, 3])\n",
            "x2.shape: torch.Size([3, 3, 1])\n",
            "x0 = tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "x1 = tensor([[[1, 2, 3]],\n",
            "\n",
            "        [[4, 5, 6]],\n",
            "\n",
            "        [[7, 8, 9]]])\n",
            "x2 = tensor([[[1],\n",
            "         [2],\n",
            "         [3]],\n",
            "\n",
            "        [[4],\n",
            "         [5],\n",
            "         [6]],\n",
            "\n",
            "        [[7],\n",
            "         [8],\n",
            "         [9]]])\n",
            "x3 = tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "x3.shape = torch.Size([3, 3])\n",
            "x4 = tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "x5 = tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n"
          ]
        }
      ],
      "source": [
        "# Pytorch Basic - Tensor\n",
        "import torch\n",
        "\n",
        "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
        "y = torch.FloatTensor([[1,2,3], [4,5,6], [7,8,9]])\n",
        "\n",
        "x0 = torch.unsqueeze(x, 0)\n",
        "x1 = torch.unsqueeze(x, 1)\n",
        "x2 = torch.unsqueeze(x, 2)\n",
        "x3 = torch.squeeze(torch.squeeze(x0))\n",
        "x4 = x.view(9)\n",
        "x5 = x.view(1,3,3)\n",
        "\n",
        "print(\"x =\", x)\n",
        "print(\"y =\", y)\n",
        "\n",
        "print(\"Size:\", x.size())\n",
        "print(\"Shape:\", x.shape)\n",
        "print(\"차원(랭크):\", x.ndimension())\n",
        "\n",
        "print(\"x0.shape:\", x0.shape)\n",
        "print(\"x1.shape:\", x1.shape)\n",
        "print(\"x2.shape:\", x2.shape)\n",
        "print(\"x0 =\", x0)\n",
        "print(\"x1 =\", x1)\n",
        "print(\"x2 =\", x2)\n",
        "\n",
        "print(\"x3 =\", x3)\n",
        "print(\"x3.shape =\", x3.shape)\n",
        "\n",
        "print(\"x4 =\", x4)\n",
        "print(\"x5 =\", x5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch Basic - 행렬 연산\n",
        "import torch\n",
        "\n",
        "x = torch.FloatTensor([[1,2], [3,4], [5,6]])\n",
        "w = torch.randn(1,2, dtype=torch.float)\n",
        "b = torch.randn(3,1, dtype=torch.float)\n",
        "result = torch.mm(x, torch.t(w)) + b\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zammeeR0SJ8S",
        "outputId": "27456077-5461-4876-dd59-ea611f1ba5ac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -3.4566],\n",
            "        [ -7.5675],\n",
            "        [-12.3816]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch Basic - Autograd: 기울기 계산\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "a = w*3\n",
        "l = a**2\n",
        "l.backward()\n",
        "\n",
        "print('l을 w로 미분한 값은', w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyIuT0QZSV40",
        "outputId": "acacb2b1-79ae-4337-8a39-3ab32b60b010"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l을 w로 미분한 값은 tensor(18.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression with Pytorch\n",
        "import torch\n",
        "\n",
        "x = torch.FloatTensor([[1,2], [3,2], [3,7], [1,1], [1,0]])\n",
        "y = torch.FloatTensor([[4], [8], [23], [1], [-2]])\n",
        "\n",
        "W = torch.zeros(2,1)\n",
        "b = torch.zeros(1,1)\n",
        "lr = 0.01\n",
        "\n",
        "for epoch in range(3001):\n",
        "  W.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  hypothesis = torch.mm(x, W) + b\n",
        "  cost = torch.mean((hypothesis - y) ** 2)\n",
        "\n",
        "  cost.backward()\n",
        "\n",
        "  with torch.no_grad() as grd:\n",
        "    W = W - lr * W.grad\n",
        "    b = b - lr * b.grad\n",
        "  if epoch % 100 == 0:\n",
        "    print( 'epoch: {}, cost: {:.6f}, W: {}, b: {}'.format(epoch, cost.item(), W.squeeze(), b))\n",
        "\n",
        "# x = [5,10]일 때, y의 값 (Test)\n",
        "x_test = torch.FloatTensor([[5,10]])\n",
        "test_result = torch.mm(x_test, W) + b\n",
        "\n",
        "print(test_result.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dm6sYQilSk4O",
        "outputId": "58d04686-e766-4477-b207-637c5ed38da5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 122.800003, W: tensor([0.3840, 0.7440]), b: tensor([[0.1360]])\n",
            "epoch: 100, cost: 1.533757, W: tensor([0.6226, 3.1603]), b: tensor([[-1.3651]])\n",
            "epoch: 200, cost: 0.758241, W: tensor([0.9143, 3.1864]), b: tensor([[-2.1790]])\n",
            "epoch: 300, cost: 0.389288, W: tensor([1.2106, 3.1417]), b: tensor([[-2.7023]])\n",
            "epoch: 400, cost: 0.200058, W: tensor([1.4328, 3.1025]), b: tensor([[-3.0705]])\n",
            "epoch: 500, cost: 0.102813, W: tensor([1.5932, 3.0736]), b: tensor([[-3.3338]])\n",
            "epoch: 600, cost: 0.052838, W: tensor([1.7084, 3.0528]), b: tensor([[-3.5224]])\n",
            "epoch: 700, cost: 0.027154, W: tensor([1.7909, 3.0378]), b: tensor([[-3.6576]])\n",
            "epoch: 800, cost: 0.013955, W: tensor([1.8501, 3.0271]), b: tensor([[-3.7546]])\n",
            "epoch: 900, cost: 0.007172, W: tensor([1.8926, 3.0194]), b: tensor([[-3.8241]])\n",
            "epoch: 1000, cost: 0.003686, W: tensor([1.9230, 3.0139]), b: tensor([[-3.8739]])\n",
            "epoch: 1100, cost: 0.001894, W: tensor([1.9448, 3.0100]), b: tensor([[-3.9096]])\n",
            "epoch: 1200, cost: 0.000973, W: tensor([1.9604, 3.0072]), b: tensor([[-3.9352]])\n",
            "epoch: 1300, cost: 0.000500, W: tensor([1.9716, 3.0051]), b: tensor([[-3.9535]])\n",
            "epoch: 1400, cost: 0.000257, W: tensor([1.9797, 3.0037]), b: tensor([[-3.9667]])\n",
            "epoch: 1500, cost: 0.000132, W: tensor([1.9854, 3.0026]), b: tensor([[-3.9761]])\n",
            "epoch: 1600, cost: 0.000068, W: tensor([1.9895, 3.0019]), b: tensor([[-3.9829]])\n",
            "epoch: 1700, cost: 0.000035, W: tensor([1.9925, 3.0014]), b: tensor([[-3.9877]])\n",
            "epoch: 1800, cost: 0.000018, W: tensor([1.9946, 3.0010]), b: tensor([[-3.9912]])\n",
            "epoch: 1900, cost: 0.000009, W: tensor([1.9961, 3.0007]), b: tensor([[-3.9937]])\n",
            "epoch: 2000, cost: 0.000005, W: tensor([1.9972, 3.0005]), b: tensor([[-3.9955]])\n",
            "epoch: 2100, cost: 0.000002, W: tensor([1.9980, 3.0004]), b: tensor([[-3.9968]])\n",
            "epoch: 2200, cost: 0.000001, W: tensor([1.9986, 3.0003]), b: tensor([[-3.9977]])\n",
            "epoch: 2300, cost: 0.000001, W: tensor([1.9990, 3.0002]), b: tensor([[-3.9983]])\n",
            "epoch: 2400, cost: 0.000000, W: tensor([1.9993, 3.0001]), b: tensor([[-3.9988]])\n",
            "epoch: 2500, cost: 0.000000, W: tensor([1.9995, 3.0001]), b: tensor([[-3.9991]])\n",
            "epoch: 2600, cost: 0.000000, W: tensor([1.9996, 3.0001]), b: tensor([[-3.9994]])\n",
            "epoch: 2700, cost: 0.000000, W: tensor([1.9997, 3.0000]), b: tensor([[-3.9996]])\n",
            "epoch: 2800, cost: 0.000000, W: tensor([1.9998, 3.0000]), b: tensor([[-3.9997]])\n",
            "epoch: 2900, cost: 0.000000, W: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n",
            "epoch: 3000, cost: 0.000000, W: tensor([1.9999, 3.0000]), b: tensor([[-3.9998]])\n",
            "35.99984359741211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression with Scikit-learn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = [[1,2], [3,2], [3,7], [1,1], [1,0]]\n",
        "y = [[4], [8], [23], [1], [-2]]\n",
        "\n",
        "lr = LinearRegression() # 모델 생성\n",
        "lr.fit(x, y) # 학습 (피팅)\n",
        "\n",
        "print(lr.coef_, lr.intercept_)\n",
        "print(lr.predict([[5,10]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYfSdGCLVL_s",
        "outputId": "42c879ae-13da-4bc3-be6b-8a8736576ddc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2. 3.]] [-4.]\n",
            "[[36.]]\n"
          ]
        }
      ]
    }
  ]
}