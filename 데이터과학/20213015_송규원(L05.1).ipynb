{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-Z-z_MIZWFl",
        "outputId": "a3e47705-8114-4c4c-80f1-f93eaae9dc85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w : tensor([[-0.3273]]), b : tensor([[0.5170]]), cost : 0.6410772800445557\n",
            "w : tensor([[-1.4745]]), b : tensor([[4.4785]]), cost : 0.41875192523002625\n",
            "w : tensor([[-1.9115]]), b : tensor([[5.8134]]), cost : 0.3982717990875244\n",
            "w : tensor([[-2.1831]]), b : tensor([[6.6361]]), cost : 0.3906193673610687\n",
            "w : tensor([[-2.3737]]), b : tensor([[7.2108]]), cost : 0.3869032561779022\n",
            "w : tensor([[-2.5155]]), b : tensor([[7.6371]]), cost : 0.38486385345458984\n",
            "w : tensor([[-2.6246]]), b : tensor([[7.9645]]), cost : 0.3836621046066284\n",
            "w : tensor([[-2.7104]]), b : tensor([[8.2218]]), cost : 0.382920503616333\n",
            "w : tensor([[-2.7790]]), b : tensor([[8.4272]]), cost : 0.3824479877948761\n",
            "w : tensor([[-2.8345]]), b : tensor([[8.5932]]), cost : 0.3821395933628082\n",
            "w : tensor([[-2.8797]]), b : tensor([[8.7285]]), cost : 0.38193491101264954\n",
            "w : tensor([[-2.9168]]), b : tensor([[8.8395]]), cost : 0.3817969858646393\n",
            "w : tensor([[-2.9475]]), b : tensor([[8.9310]]), cost : 0.38170328736305237\n",
            "w : tensor([[-2.9729]]), b : tensor([[9.0069]]), cost : 0.3816389739513397\n",
            "w : tensor([[-2.9940]]), b : tensor([[9.0699]]), cost : 0.3815945088863373\n",
            "w : tensor([[-3.0116]]), b : tensor([[9.1225]]), cost : 0.38156357407569885\n",
            "w : tensor([[-3.0263]]), b : tensor([[9.1664]]), cost : 0.38154199719429016\n",
            "w : tensor([[-3.0386]]), b : tensor([[9.2031]]), cost : 0.38152697682380676\n",
            "w : tensor([[-3.0489]]), b : tensor([[9.2339]]), cost : 0.3815164268016815\n",
            "w : tensor([[-3.0576]]), b : tensor([[9.2597]]), cost : 0.3815089166164398\n",
            "w : tensor([[-3.0649]]), b : tensor([[9.2815]]), cost : 0.3815036714076996\n",
            "w : tensor([[-3.0710]]), b : tensor([[9.2997]]), cost : 0.3814999759197235\n",
            "w : tensor([[-3.0761]]), b : tensor([[9.3151]]), cost : 0.38149726390838623\n",
            "w : tensor([[-3.0805]]), b : tensor([[9.3280]]), cost : 0.3814953565597534\n",
            "w : tensor([[-3.0841]]), b : tensor([[9.3389]]), cost : 0.38149407505989075\n",
            "w : tensor([[-3.0872]]), b : tensor([[9.3481]]), cost : 0.38149312138557434\n",
            "w : tensor([[-3.0898]]), b : tensor([[9.3558]]), cost : 0.3814924657344818\n",
            "w : tensor([[-3.0920]]), b : tensor([[9.3624]]), cost : 0.3814920485019684\n",
            "w : tensor([[-3.0938]]), b : tensor([[9.3679]]), cost : 0.38149166107177734\n",
            "w : tensor([[-3.0954]]), b : tensor([[9.3725]]), cost : 0.3814913034439087\n",
            "w : tensor([[-3.0967]]), b : tensor([[9.3764]]), cost : 0.38149121403694153\n"
          ]
        }
      ],
      "source": [
        "#Pytorch로 Logistic Regression 구현\n",
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "w = torch.randn(1, 1)\n",
        "b = torch.randn(1, 1)\n",
        "\n",
        "lr = 1.0\n",
        "\n",
        "for epoch in range(3001):\n",
        "  w.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, w) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  cost.backward() #기울기 계산\n",
        "  with torch.no_grad():\n",
        "    w = w - lr * w.grad\n",
        "    b = b - lr * b.grad\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"w : {w}, b : {b}, cost : {cost}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test : x = [4.5] 혹은 [1.1]일 때, y는 0일까 1일까?\n",
        "with torch.no_grad():\n",
        "  x_test = torch.FloatTensor([[4.5], [1.1]])\n",
        "  h_test = torch.sigmoid(torch.mm(x_test, w) + b)\n",
        "  \n",
        "  h_test[h_test > 0.5] = 1\n",
        "  h_test[h_test <= 0.5] = 0\n",
        "\n",
        "  print(h_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DhAqK0ce4ry",
        "outputId": "cec71f06-0c10-433d-8dfb-e86bb72eb290"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#여러가지 Optimizer 사용해보기 - SGD\n",
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "w = torch.randn(1, 1, requires_grad=True)\n",
        "b = torch.randn(1, 1, requires_grad=True)\n",
        "\n",
        "optim = torch.optim.SGD([w, b], lr = 1.0)\n",
        "\n",
        "for epoch in range(3001):\n",
        "  w.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, w) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  optim.zero_grad() #w, b의 기울기 초기화\n",
        "  cost.backward() #기울기 계산\n",
        "  optim.step() #w, b 값 갱신\n",
        "\n",
        "  with torch.no_grad():\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"w : {w.item()}, b : {b}, cost : {cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdm7XMLviJvV",
        "outputId": "5e08d0bb-d665-41c0-b647-0f8ae5aa1183"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w : -0.08795535564422607, b : tensor([[-0.6569]], requires_grad=True), cost : 2.2564635276794434\n",
            "w : -1.4201409816741943, b : tensor([[4.3110]], requires_grad=True), cost : 0.422262579202652\n",
            "w : -1.881203293800354, b : tensor([[5.7214]], requires_grad=True), cost : 0.3993283212184906\n",
            "w : -2.1627893447875977, b : tensor([[6.5747]], requires_grad=True), cost : 0.39108896255493164\n",
            "w : -2.358966827392578, b : tensor([[7.1664]], requires_grad=True), cost : 0.3871488869190216\n",
            "w : -2.5042922496795654, b : tensor([[7.6035]], requires_grad=True), cost : 0.38500431180000305\n",
            "w : -2.6158485412597656, b : tensor([[7.9384]], requires_grad=True), cost : 0.38374701142311096\n",
            "w : -2.7034876346588135, b : tensor([[8.2011]], requires_grad=True), cost : 0.38297387957572937\n",
            "w : -2.7734534740448, b : tensor([[8.4106]], requires_grad=True), cost : 0.38248229026794434\n",
            "w : -2.829969882965088, b : tensor([[8.5797]], requires_grad=True), cost : 0.3821622133255005\n",
            "w : -2.876025438308716, b : tensor([[8.7175]], requires_grad=True), cost : 0.3819500207901001\n",
            "w : -2.9138119220733643, b : tensor([[8.8304]], requires_grad=True), cost : 0.38180723786354065\n",
            "w : -2.944981813430786, b : tensor([[8.9235]], requires_grad=True), cost : 0.3817102611064911\n",
            "w : -2.9708011150360107, b : tensor([[9.0007]], requires_grad=True), cost : 0.38164380192756653\n",
            "w : -2.9922614097595215, b : tensor([[9.0647]], requires_grad=True), cost : 0.38159775733947754\n",
            "w : -3.0101497173309326, b : tensor([[9.1182]], requires_grad=True), cost : 0.3815659284591675\n",
            "w : -3.0250914096832275, b : tensor([[9.1628]], requires_grad=True), cost : 0.38154372572898865\n",
            "w : -3.037597417831421, b : tensor([[9.2001]], requires_grad=True), cost : 0.3815280497074127\n",
            "w : -3.048079490661621, b : tensor([[9.2314]], requires_grad=True), cost : 0.3815171718597412\n",
            "w : -3.056875705718994, b : tensor([[9.2576]], requires_grad=True), cost : 0.3815094530582428\n",
            "w : -3.064265251159668, b : tensor([[9.2797]], requires_grad=True), cost : 0.381504088640213\n",
            "w : -3.070478677749634, b : tensor([[9.2982]], requires_grad=True), cost : 0.381500244140625\n",
            "w : -3.0757076740264893, b : tensor([[9.3138]], requires_grad=True), cost : 0.38149747252464294\n",
            "w : -3.080111026763916, b : tensor([[9.3269]], requires_grad=True), cost : 0.38149556517601013\n",
            "w : -3.08381986618042, b : tensor([[9.3380]], requires_grad=True), cost : 0.38149407505989075\n",
            "w : -3.0869460105895996, b : tensor([[9.3473]], requires_grad=True), cost : 0.3814931809902191\n",
            "w : -3.0895822048187256, b : tensor([[9.3552]], requires_grad=True), cost : 0.3814925253391266\n",
            "w : -3.0918049812316895, b : tensor([[9.3618]], requires_grad=True), cost : 0.3814919888973236\n",
            "w : -3.0936808586120605, b : tensor([[9.3674]], requires_grad=True), cost : 0.38149169087409973\n",
            "w : -3.095264434814453, b : tensor([[9.3721]], requires_grad=True), cost : 0.38149139285087585\n",
            "w : -3.0966010093688965, b : tensor([[9.3761]], requires_grad=True), cost : 0.3814912736415863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#여러가지 Optimizer 사용해보기 - Adam\n",
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "w = torch.randn(1, 1, requires_grad=True)\n",
        "b = torch.randn(1, 1, requires_grad=True)\n",
        "\n",
        "optim = torch.optim.Adam([w, b], lr = 1.0)\n",
        "\n",
        "for epoch in range(3001):\n",
        "  w.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, w) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  optim.zero_grad() #w, b의 기울기 초기화\n",
        "  cost.backward() #기울기 계산\n",
        "  optim.step() #w, b 값 갱신\n",
        "\n",
        "  with torch.no_grad():\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"w : {w.item()}, b : {b}, cost : {cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_cV-KSqkvHu",
        "outputId": "9e867157-c898-4e68-acfb-efbc02e65513"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w : -0.002786099910736084, b : tensor([[-0.8647]], requires_grad=True), cost : 1.6751912832260132\n",
            "w : -2.893038034439087, b : tensor([[8.7623]], requires_grad=True), cost : 0.38191497325897217\n",
            "w : -3.0864624977111816, b : tensor([[9.3459]], requires_grad=True), cost : 0.38149356842041016\n",
            "w : -3.1034326553344727, b : tensor([[9.3965]], requires_grad=True), cost : 0.3814907968044281\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.1038522720336914, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.1038529872894287, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908564090729\n",
            "w : -3.1038529872894287, b : tensor([[9.3978]], requires_grad=True), cost : 0.38149070739746094\n",
            "w : -3.1038522720336914, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.1038525104522705, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814907371997833\n",
            "w : -3.7185890674591064, b : tensor([[10.8418]], requires_grad=True), cost : 0.38514208793640137\n",
            "w : -3.1059770584106445, b : tensor([[9.4024]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.1038596630096436, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.1038529872894287, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.103853225708008, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.103853225708008, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.103853225708008, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n",
            "w : -3.103853225708008, b : tensor([[9.3978]], requires_grad=True), cost : 0.3814908266067505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#여러가지 Optimizer 사용해보기 - Adadelta\n",
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "w = torch.randn(1, 1, requires_grad=True)\n",
        "b = torch.randn(1, 1, requires_grad=True)\n",
        "\n",
        "optim = torch.optim.Adadelta([w, b])\n",
        "\n",
        "for epoch in range(3001):\n",
        "  w.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, w) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  optim.zero_grad() #w, b의 기울기 초기화\n",
        "  cost.backward() #기울기 계산\n",
        "  optim.step() #w, b 값 갱신\n",
        "\n",
        "  with torch.no_grad():\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"w : {w.item()}, b : {b}, cost : {cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuTreIRHkyQR",
        "outputId": "e7f3ab0e-4f30-4693-8c19-be66105afc0d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w : -0.7775095105171204, b : tensor([[1.4667]], requires_grad=True), cost : 0.6042793393135071\n",
            "w : -0.6018723845481873, b : tensor([[1.7272]], requires_grad=True), cost : 0.5229700207710266\n",
            "w : -0.6918208599090576, b : tensor([[2.0149]], requires_grad=True), cost : 0.505416989326477\n",
            "w : -0.8139860033988953, b : tensor([[2.4030]], requires_grad=True), cost : 0.48492586612701416\n",
            "w : -0.9515881538391113, b : tensor([[2.8386]], requires_grad=True), cost : 0.465705543756485\n",
            "w : -1.098205327987671, b : tensor([[3.2996]], requires_grad=True), cost : 0.4489485025405884\n",
            "w : -1.2502728700637817, b : tensor([[3.7747]], requires_grad=True), cost : 0.43481698632240295\n",
            "w : -1.4056321382522583, b : tensor([[4.2570]], requires_grad=True), cost : 0.42310479283332825\n",
            "w : -1.562705397605896, b : tensor([[4.7418]], requires_grad=True), cost : 0.4135073721408844\n",
            "w : -1.720046877861023, b : tensor([[5.2249]], requires_grad=True), cost : 0.40572383999824524\n",
            "w : -1.8760886192321777, b : tensor([[5.7017]], requires_grad=True), cost : 0.39948734641075134\n",
            "w : -2.028973340988159, b : tensor([[6.1669]], requires_grad=True), cost : 0.3945677578449249\n",
            "w : -2.1764373779296875, b : tensor([[6.6141]], requires_grad=True), cost : 0.390765905380249\n",
            "w : -2.315741539001465, b : tensor([[7.0351]], requires_grad=True), cost : 0.3879053294658661\n",
            "w : -2.443749189376831, b : tensor([[7.4210]], requires_grad=True), cost : 0.3858236074447632\n",
            "w : -2.5573062896728516, b : tensor([[7.7625]], requires_grad=True), cost : 0.38436686992645264\n",
            "w : -2.6541147232055664, b : tensor([[8.0531]], requires_grad=True), cost : 0.3833872377872467\n",
            "w : -2.733818292617798, b : tensor([[8.2920]], requires_grad=True), cost : 0.3827475607395172\n",
            "w : -2.7982733249664307, b : tensor([[8.4849]], requires_grad=True), cost : 0.38233351707458496\n",
            "w : -2.8504045009613037, b : tensor([[8.6409]], requires_grad=True), cost : 0.38206279277801514\n",
            "w : -2.892893075942993, b : tensor([[8.7679]], requires_grad=True), cost : 0.3818829357624054\n",
            "w : -2.9277751445770264, b : tensor([[8.8721]], requires_grad=True), cost : 0.3817615509033203\n",
            "w : -2.9565720558166504, b : tensor([[8.9582]], requires_grad=True), cost : 0.3816789388656616\n",
            "w : -2.9804463386535645, b : tensor([[9.0295]], requires_grad=True), cost : 0.3816221058368683\n",
            "w : -3.0003063678741455, b : tensor([[9.0888]], requires_grad=True), cost : 0.3815828263759613\n",
            "w : -3.0168697834014893, b : tensor([[9.1382]], requires_grad=True), cost : 0.3815555274486542\n",
            "w : -3.030717372894287, b : tensor([[9.1795]], requires_grad=True), cost : 0.3815363347530365\n",
            "w : -3.0423121452331543, b : tensor([[9.2142]], requires_grad=True), cost : 0.38152292370796204\n",
            "w : -3.052037000656128, b : tensor([[9.2432]], requires_grad=True), cost : 0.3815135955810547\n",
            "w : -3.0602009296417236, b : tensor([[9.2675]], requires_grad=True), cost : 0.38150689005851746\n",
            "w : -3.067060947418213, b : tensor([[9.2880]], requires_grad=True), cost : 0.38150230050086975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#여러가지 Optimizer 사용해보기 - Adagrad\n",
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "w = torch.randn(1, 1, requires_grad=True)\n",
        "b = torch.randn(1, 1, requires_grad=True)\n",
        "\n",
        "optim = torch.optim.Adagrad([w, b])\n",
        "\n",
        "for epoch in range(3001):\n",
        "  w.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, w) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  optim.zero_grad() #w, b의 기울기 초기화\n",
        "  cost.backward() #기울기 계산\n",
        "  optim.step() #w, b 값 갱신\n",
        "\n",
        "  with torch.no_grad():\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"w : {w.item()}, b : {b}, cost : {cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXvX_n7Fk8cd",
        "outputId": "7d0fcd84-e34d-4cb6-92e6-cb8bb7f055ba"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w : -1.219886064529419, b : tensor([[1.9201]], requires_grad=True), cost : 0.7698313593864441\n",
            "w : -1.0553241968154907, b : tensor([[2.0861]], requires_grad=True), cost : 0.6019625663757324\n",
            "w : -0.989158034324646, b : tensor([[2.1548]], requires_grad=True), cost : 0.5544512867927551\n",
            "w : -0.9446275234222412, b : tensor([[2.2029]], requires_grad=True), cost : 0.5287063121795654\n",
            "w : -0.9120709300041199, b : tensor([[2.2399]], requires_grad=True), cost : 0.5132724642753601\n",
            "w : -0.8875250816345215, b : tensor([[2.2698]], requires_grad=True), cost : 0.5036017298698425\n",
            "w : -0.8688119649887085, b : tensor([[2.2946]], requires_grad=True), cost : 0.4973802864551544\n",
            "w : -0.8545355200767517, b : tensor([[2.3157]], requires_grad=True), cost : 0.49329325556755066\n",
            "w : -0.8437129855155945, b : tensor([[2.3340]], requires_grad=True), cost : 0.49054864048957825\n",
            "w : -0.8356142044067383, b : tensor([[2.3501]], requires_grad=True), cost : 0.48865604400634766\n",
            "w : -0.8296774625778198, b : tensor([[2.3645]], requires_grad=True), cost : 0.4873068034648895\n",
            "w : -0.8254616856575012, b : tensor([[2.3776]], requires_grad=True), cost : 0.4863046407699585\n",
            "w : -0.82261723279953, b : tensor([[2.3895]], requires_grad=True), cost : 0.4855251610279083\n",
            "w : -0.8208648562431335, b : tensor([[2.4007]], requires_grad=True), cost : 0.4848887622356415\n",
            "w : -0.8199819326400757, b : tensor([[2.4111]], requires_grad=True), cost : 0.48434457182884216\n",
            "w : -0.8197892904281616, b : tensor([[2.4210]], requires_grad=True), cost : 0.4838605225086212\n",
            "w : -0.8201457858085632, b : tensor([[2.4305]], requires_grad=True), cost : 0.4834159314632416\n",
            "w : -0.8209368586540222, b : tensor([[2.4396]], requires_grad=True), cost : 0.4829977750778198\n",
            "w : -0.8220716118812561, b : tensor([[2.4484]], requires_grad=True), cost : 0.48259755969047546\n",
            "w : -0.8234769701957703, b : tensor([[2.4570]], requires_grad=True), cost : 0.4822101294994354\n",
            "w : -0.8250954747200012, b : tensor([[2.4653]], requires_grad=True), cost : 0.48183193802833557\n",
            "w : -0.826880693435669, b : tensor([[2.4735]], requires_grad=True), cost : 0.481460839509964\n",
            "w : -0.8287960886955261, b : tensor([[2.4816]], requires_grad=True), cost : 0.4810955822467804\n",
            "w : -0.8308124542236328, b : tensor([[2.4895]], requires_grad=True), cost : 0.48073503375053406\n",
            "w : -0.8329063653945923, b : tensor([[2.4973]], requires_grad=True), cost : 0.4803788363933563\n",
            "w : -0.8350595235824585, b : tensor([[2.5051]], requires_grad=True), cost : 0.48002633452415466\n",
            "w : -0.8372573256492615, b : tensor([[2.5127]], requires_grad=True), cost : 0.4796774089336395\n",
            "w : -0.8394877910614014, b : tensor([[2.5203]], requires_grad=True), cost : 0.47933176159858704\n",
            "w : -0.8417420983314514, b : tensor([[2.5278]], requires_grad=True), cost : 0.47898945212364197\n",
            "w : -0.8440126180648804, b : tensor([[2.5353]], requires_grad=True), cost : 0.4786502420902252\n",
            "w : -0.8462933897972107, b : tensor([[2.5427]], requires_grad=True), cost : 0.4783141314983368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#여러가지 Optimizer 사용해보기 - RMSprop\n",
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]])\n",
        "y_train = torch.FloatTensor([[1],[1],[1],[0],[0],[0],[0],[1],[0],[1],[1],[1]])\n",
        "\n",
        "w = torch.randn(1, 1, requires_grad=True)\n",
        "b = torch.randn(1, 1, requires_grad=True)\n",
        "\n",
        "optim = torch.optim.RMSprop([w, b])\n",
        "\n",
        "for epoch in range(3001):\n",
        "  w.requires_grad_(True)\n",
        "  b.requires_grad_(True)\n",
        "\n",
        "  h = torch.sigmoid(torch.mm(x_train, w) + b)\n",
        "  cost = torch.mean(-y_train * torch.log(h) - (1 - y_train) * torch.log(1 - h))\n",
        "\n",
        "  optim.zero_grad() #w, b의 기울기 초기화\n",
        "  cost.backward() #기울기 계산\n",
        "  optim.step() #w, b 값 갱신\n",
        "\n",
        "  with torch.no_grad():\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"w : {w.item()}, b : {b}, cost : {cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aBav6h0k_Q6",
        "outputId": "9d943424-b392-4b9f-c3f7-d1a5037e3807"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w : -1.2910593748092651, b : tensor([[0.6139]], requires_grad=True), cost : 1.5069055557250977\n",
            "w : -0.5772872567176819, b : tensor([[1.7015]], requires_grad=True), cost : 0.5251129865646362\n",
            "w : -0.7340565323829651, b : tensor([[2.1902]], requires_grad=True), cost : 0.49598872661590576\n",
            "w : -0.9161472320556641, b : tensor([[2.7556]], requires_grad=True), cost : 0.4692431688308716\n",
            "w : -1.115491271018982, b : tensor([[3.3729]], requires_grad=True), cost : 0.4466727674007416\n",
            "w : -1.3258168697357178, b : tensor([[4.0214]], requires_grad=True), cost : 0.42858874797821045\n",
            "w : -1.542688250541687, b : tensor([[4.6869]], requires_grad=True), cost : 0.4145396947860718\n",
            "w : -1.7627344131469727, b : tensor([[5.3587]], requires_grad=True), cost : 0.4038684368133545\n",
            "w : -1.982887625694275, b : tensor([[6.0277]], requires_grad=True), cost : 0.39595118165016174\n",
            "w : -2.202157735824585, b : tensor([[6.6813]], requires_grad=True), cost : 0.3902895450592041\n",
            "w : -2.400393486022949, b : tensor([[7.2897]], requires_grad=True), cost : 0.38648784160614014\n",
            "w : -2.5955264568328857, b : tensor([[7.8416]], requires_grad=True), cost : 0.38415423035621643\n",
            "w : -2.751315116882324, b : tensor([[8.3206]], requires_grad=True), cost : 0.3827122449874878\n",
            "w : -2.878509283065796, b : tensor([[8.6999]], requires_grad=True), cost : 0.3820136487483978\n",
            "w : -2.9678311347961426, b : tensor([[8.9708]], requires_grad=True), cost : 0.3816972076892853\n",
            "w : -3.0251834392547607, b : tensor([[9.1456]], requires_grad=True), cost : 0.38157132267951965\n",
            "w : -3.0605101585388184, b : tensor([[9.2503]], requires_grad=True), cost : 0.381531685590744\n",
            "w : -3.081531047821045, b : tensor([[9.3110]], requires_grad=True), cost : 0.3815230131149292\n",
            "w : -3.093360662460327, b : tensor([[9.3462]], requires_grad=True), cost : 0.3815191984176636\n",
            "w : -3.0999646186828613, b : tensor([[9.3665]], requires_grad=True), cost : 0.38151609897613525\n",
            "w : -3.1038529872894287, b : tensor([[9.3781]], requires_grad=True), cost : 0.38151559233665466\n",
            "w : -3.106135606765747, b : tensor([[9.3846]], requires_grad=True), cost : 0.38151606917381287\n",
            "w : -3.1073992252349854, b : tensor([[9.3884]], requires_grad=True), cost : 0.3815159499645233\n",
            "w : -3.1081039905548096, b : tensor([[9.3906]], requires_grad=True), cost : 0.3815157115459442\n",
            "w : -3.1085214614868164, b : tensor([[9.3918]], requires_grad=True), cost : 0.3815157115459442\n",
            "w : -3.1087679862976074, b : tensor([[9.3925]], requires_grad=True), cost : 0.381515771150589\n",
            "w : -3.1089041233062744, b : tensor([[9.3929]], requires_grad=True), cost : 0.3815157413482666\n",
            "w : -3.1089773178100586, b : tensor([[9.3931]], requires_grad=True), cost : 0.3815157115459442\n",
            "w : -3.1090235710144043, b : tensor([[9.3933]], requires_grad=True), cost : 0.3815157413482666\n",
            "w : -3.1090500354766846, b : tensor([[9.3933]], requires_grad=True), cost : 0.381515771150589\n",
            "w : -3.109065294265747, b : tensor([[9.3934]], requires_grad=True), cost : 0.3815157413482666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matplotlib으로 결과 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "with torch.no_grad():\n",
        "  plt.scatter(x_train, y_train, c=\"black\")\n",
        "\n",
        "  x_tmp = torch.linspace(0, 5, 100).unsqueeze(1)\n",
        "  y_tmp = torch.sigmoid(torch.mm(x_tmp, w) + b)\n",
        "\n",
        "  plt.plot(x_tmp, y_tmp, \"r\")\n",
        "  plt.ylabel(\"Probability of 1 (Y)\")\n",
        "  plt.xlabel(\"Input (X)\")\n",
        "  \n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "hW2Iyr5dlTE9",
        "outputId": "58d19a39-1b4e-4c43-97b4-f1f64d133f15"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn에서 Logistic Regression 사용\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train = [[1],[2],[3],[4],[5],[2.5],[3.5],[0],[3.1],[2.7],[2.8],[2.9]]\n",
        "y_train = [1,1,1,0,0,0,0,1,0,1,1,1] #입력 방식이 pytorch와 다름, 1차원 배열\n",
        "\n",
        "model = LogisticRegression(penalty='none')\n",
        "#너무 큰 값과 너무 작은 값에 penalty를 주는 것 >> none regularization 안 함\n",
        "\n",
        "model.fit(x_train, y_train) #학습 시킴\n",
        "\n",
        "#w와 b에 해당하는 값 출력\n",
        "print(model.coef_, model.intercept_)\n",
        "\n",
        "#새로운 x값이 주어질 때 y값 예측해보기\n",
        "x_test = [[4.5],[1.1]]\n",
        "test_result = model.predict(x_test)\n",
        "print(test_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NitjpRjhnSqC",
        "outputId": "055fa9ad-ff91-4704-ec2f-98bc203fa4c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.10385806]] [9.39776831]\n",
            "[0 1]\n"
          ]
        }
      ]
    }
  ]
}